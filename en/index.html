<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta property="og:title" content="Lorenzo Siena's Portfolio">
    <meta property="og:description" content="All of Lorenzo's opensource projects">
    <meta property="og:image" content="https://lorenzosiena.github.io/media/logo_site.jpg">
    <meta property="og:url" content="https://lorenzosiena.github.io/it/">
    <meta property="og:type" content="website">
    <link rel="apple-touch-icon" sizes="180x180" href="/static/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/static/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/static/icons/favicon-16x16.png">
    <link rel="shortcut icon" href="/static/icons/favicon.ico" type="image/x-icon">
    <link rel="manifest" href="/static/icons/site-en.webmanifest">
    <title>Lorenzo's Portfolio</title>
    <script src="/js/index.js" defer></script>

    <link rel="stylesheet" href="/css/index.css">


</head>

<body>

    <header class="portfolio-header">

        <h1>Lorenzo Siena's <br> portfolio</h1>

        <div class="social-links">


            <a href="https://www.linkedin.com/in/lorenzo-siena-ba213319a/" target="_blank" rel="noopener noreferrer"
                aria-label="Go to LinkedIn profile">

                <svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="50" height="50" viewBox="0 0 50 50">
                    <path
                        d="M41,4H9C6.24,4,4,6.24,4,9v32c0,2.76,2.24,5,5,5h32c2.76,0,5-2.24,5-5V9C46,6.24,43.76,4,41,4z M17,20v19h-6V20H17z M11,14.47c0-1.4,1.2-2.47,3-2.47s2.93,1.07,3,2.47c0,1.4-1.12,2.53-3,2.53C12.2,17,11,15.87,11,14.47z M39,39h-6c0,0,0-9.26,0-10 c0-2-1-4-3.5-4.04h-0.08C27,24.96,26,27.02,26,29c0,0.91,0,10,0,10h-6V20h6v2.56c0,0,1.93-2.56,5.81-2.56 c3.97,0,7.19,2.73,7.19,8.26V39z">
                    </path>
                </svg>
                <span class="social-text">Find me on LinkedIn</span>
            </a>
            <a href="https://rxresu.me/lorenzo.siena.dev/lorenzo-siena-ai-backend-eng" target="_blank" rel="noopener noreferrer"
                aria-label="English">
                <img width="48" height="48"
                    src="https://img.icons8.com/?size=100&id=4LOAXHv8j8Ef&format=png&color=000000" alt="curriculum" />
                <span class="social-text">CV</span>
            </a>

            <a href="mailto:lorenzo.siena.dev@gmail.com" rel="noopener noreferrer" aria-label="English">
                <img width="48" height="48"
                    src="https://img.icons8.com/?size=100&id=X0mEIh0RyDdL&format=png&color=000000" alt="mail" />
                <span class="social-text">Send me an email</span>
            </a>
            <a id="change-language" href="/it/" rel="noopener noreferrer" aria-label="Italian">
                <img width="48" height="48" src="https://img.icons8.com/color/48/italy.png"
                    alt="Change language to italian" />
                <span class="social-text">Italiano</span>
            </a>

        </div>

    </header>


     <div id="next-project" style="padding:0 ;padding-left: 1rem;" >
    
        <p>In my next projects, I will be working with <b>Langflow</b>, <b>n8n</b> and <b>CrewAI</b>  üí°ü§ñ</p>

    </div>


<div class="portfolio-block">

    <div class="tag-container">
        <div class="bookmark-tag">AI & IoT</div>
    </div>

    <div class="portfolio-text">

        <h2 class="portfolio-title">Little John ‚Äî A LangChain IoT Agent</h2>
        <a href="#">

            <picture>
                <img class="portfolio-image" src="/media/little_john_logo.jpg" alt="Little John Logo" />
            </picture>

        </a>

        <h3 class="portfolio-subtitle">A local voice-controlled AI agent built with LangChain 1.0</h3>

        <div class="project-details-content">

            <p>
                <strong>Little John</strong> is a <strong>LangChain ReAct Agent</strong> powered by Gemini LLM, designed as a Python-based voice assistant that processes natural language entirely on-device.
<br> It uses a <strong>Push-to-Talk</strong> system for activation, <strong>Whisper</strong> for local speech recognition, and a local TTS engine for responses.
<br>Through <strong>Microdot</strong> and <strong>GPIOZero</strong>, it can interact with the physical world, for example, turning on LEDs or executing other <strong>IoT actions</strong>.
            </p>

            

            <p><strong>Technologies used:</strong></p>
            <ul>
                <li><strong>Backend:</strong> LangChain 1.0 (with Gemini LLM integration)</li>
<li><strong>Voice Processing:</strong> Whisper (STT) and gTTS (TTS)</li>
<li><strong>Hardware:</strong> 2012 Dell laptop, Raspberry Pi, and microcontroller integration</li>
<li><strong>Frameworks & Libraries:</strong> Microdot (API), Pygame, Python</li>

            </ul>

            <a href="https://github.com/LorenzoSiena/Little-John--A-LangChain-IoT-Agent"
                class="btn" target="_blank" rel="noopener noreferrer">Go to project</a>

            <a href="https://drive.google.com/file/d/1tecC2FuBbb7S7qHkVKTTYiEA0oQKHGUQ/preview"
                class="btn secondary-btn" target="_blank" rel="noopener noreferrer">Watch a full demo</a>
        </div>

    </div>

</div>



    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">AI</div>
            <div class="bookmark-tag">RAG</div>
        </div>
        <div class="portfolio-text">

            <h2 class="portfolio-title">A simple Wikipedia RAG Application</h2>

            <picture>
                <source srcset="/media/wiki_rag.avif" type="image/avif">
                <source srcset="/media/wiki_rag.webp" type="image/webp">
                <img class="portfolio-image" src="/media/wiki_rag.jpg" alt="Wikipedia RAG Application">
            </picture>

            <h3 class="portfolio-subtitle">Web application with Streamlit and LlamaIndex</h3>
            <div class="project-details-content">
                <p>
                    A simple web application created with Streamlit that demonstrates the functioning of RAG (Retrieval
                    Augmented
                    Generation).
                    The app uses LlamaIndex to load and query content from Wikipedia pages related
                    to Artificial
                    Intelligence and Machine Learning,
                    providing answers based on the retrieved context.
                </p>

                <p><strong>Technologies used:</strong></p>
                <ul>
                    <li><strong>Streamlit:</strong> For the interactive user interface.</li>
                    <li><strong>LlamaIndex:</strong> Framework for building LLM applications with external data
                        (Wikipedia).</li>
                    <li><strong>OpenAI:</strong> For embedding models and language model (LLM).</li>
                    <li><strong>WikipediaReader:</strong> LlamaIndex data reader for Wikipedia content.</li>
                    <li><strong>python-dotenv:</strong> Environment variable management.</li>
                </ul>

                <a href="https://github.com/LorenzoSiena/WikipediaRAG/" class="btn" target="_blank"
                    rel="noopener noreferrer">Go
                    to project</a>
            </div>

        </div>
    </div>





    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">web</div>
        </div>
        <div class="portfolio-text">




            <h2 class="portfolio-title">HRMS ‚Äî Django with Python</h2>
            <a href="#">

                <picture>
                    <source srcset="/media/HRMS_logo.avif" type="image/avif">
                    <source srcset="/media/HRMS_logo.webp" type="image/webp">
                    <img class="portfolio-image" src="/media/HRMS_logo.jpg" alt="HRMS Screenshot" />
                </picture>

            </a>
            <h3 class="portfolio-subtitle">A Human Resources management system developed in Django</h3>
            <div class="project-details-content">

                <p>
                    A web application for the efficient management of personnel in small and medium-sized enterprises.
                    <br>
                    The system centralizes and automates key HR processes, including employee management,
                    attendance monitoring, leave management, and payroll processing.
                    <br>
                    It has a login, a registration system, authentication and also offers advanced features
                    such as performance report generation and a notification system for corporate communications.
                </p>
                <p><strong>Technologies used:</strong></p>
                <ul>
                    <li><strong>Backend:</strong> Django</li>
                    <li><strong>Frontend:</strong> HTML, CSS, JavaScript, and Bootstrap</li>
                    <li><strong>Database:</strong> SQLite</li>
                    <li><strong>Authentication:</strong> Django Authentication</li>
                </ul>
                <p><strong>Main Features:</strong></p>
                <ul>
                    <li>Complete employee management.</li>
                    <li>Request and acceptance system for attendance and leave.</li>
                    <li>Payroll management with reserved access.</li>
                    <li>Generation of detailed reports and statistics.</li>
                </ul>
                <a href="https://github.com/LorenzoSiena/HRMS-Human-Resource-Management-System" class="btn"
                    target="_blank" rel="noopener noreferrer">Go to project</a>
            </div>
        </div>


    </div>

   


    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">Android</div>
        </div>

        <h2 class="portfolio-title">CyberShop ‚Äî Java for Android</h2>
        <picture>
            <source srcset="/media/cybershop.avif" type="image/avif">
            <source srcset="/media/cybershop.webp" type="image/webp">
            <img class="portfolio-image" src="/media/cybershop.jpg" alt="CyberShop Screenshot" />
        </picture>


        <h3 class="portfolio-subtitle">Cyberpunk-themed business management app</h3>

        <div class="project-details-content">
            <p>
                Cybershop is a fictional business management app set in the year 2079.
                Its purpose is to sell cybernetic prostheses to be displayed in the app
                through augmented reality or in 3D in the form of STL files, a CAD format,
                which once purchased can be printed at home
                using a 3D printer enabled for printing biocompatible implants
                and electronic circuits.
            </p>
            <p>
                The project and demo were created for the subject <em>Mobile Programming</em>.
            </p>
            <p><strong>Technologies and Services Used:</strong></p>
            <ul>
                <li><strong>Firebase (Google Cloud Services)</strong> with:
                    <ul>
                        <li><strong>Authentication:</strong> email management, user UID and authentication</li>
                        <li><strong>Realtime Database:</strong> product list, users and wishlist</li>
                        <li><strong>Storage:</strong> saving images and STL files of products</li>
                    </ul>
                </li>
            </ul>
            <p>
                Images and texts were generated with Scribble Diffusion and ChatGPT.
                The demo is functional and responsive.
            </p>
            <p><em>Repository</em> and presentation available in PDF.</p>
            <a href="https://raw.githubusercontent.com/LorenzoSiena/CyberShop/a18a4e7e6f4c69e707207c5878f24d882fefb0fa/Cybershop_ENG.pdf"
                class="btn" target="_blank" rel="noopener noreferrer">Go to the pdf</a>
            <a href="https://github.com/LorenzoSiena/CyberShop" class="btn" target="_blank" rel="noopener noreferrer">Go
                to
                project</a>
        </div>
    </div>
    </div>




    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">Hack</div>
        </div>

        <h2 class="portfolio-title">Hack and Reverse Engineering of a Launchpad MK1</h2>


        <picture>
            <source srcset="/media/launchpad.avif" type="image/avif">
            <source srcset="/media/launchpad.webp" type="image/webp">
            <img class="portfolio-image" src="/media/launchpad.jpg"
                alt="Hack and Reverse Engineering of a Launchpad MK1" />
        </picture>

        <h3 class="portfolio-subtitle">LED Control via Python and MIDI</h3>

        <div class="project-details-content">
            <p>
                The project stems from the curiosity to explore the limits of the USB and MIDI protocol on a
                <strong>Novation Launchpad MK1</strong>. <br>Initially, through <em>fuzzing</em> with PyUSB and random
                packets,
                I managed to turn on the device's LEDs, even though it was not supported on Linux.
            </p>
            <p>
                Subsequently, I delved into its internal workings: the Launchpad is a 9x9 grid of illuminable keys
                (3 levels of red and 3 of green, combinable into yellow), which responds to MIDI commands.
                I developed three Python scripts to describe the matrix, control its LEDs, and send systematic commands,
                using a <code>wrapper</code> that leverages <code>amidi</code> as a subprocess.
            </p>
            <p>
                In addition to controlling the lights, the script receives and prints the MIDI events of the pressed
                keys,
                transforming the Launchpad into an interactive interface.
            </p>


            <p>
                In this way I was able to turn the LEDs on, off, and color them as I pleased, without official drivers,
                even creating visual effects with random packets and instant shutdown sequences.
            </p>
            <a href="/media/hackpad.mp4" class="btn" target="_blank" rel="noopener noreferrer">Go to video</a>
            <a href="https://github.com/LorenzoSiena/-WIP-Reverse-Engeneering-Usb-Protocol-on-a-Novation-Launchpad"
                class="btn" target="_blank" rel="noopener noreferrer">Go to project on GitHub</a>
            <a href="https://www.linkedin.com/posts/activity-7328426089456779265-nNAS?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC6mOeoBVQgd4y-2XUOGp19f1HXHsIYpHH8"
                class="btn" target="_blank" rel="noopener noreferrer">Go to LinkedIn update</a>
        </div>
    </div>
    </div>


    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">web</div>
        </div>

        <h2 class="portfolio-title">Server-ino ‚Äî Bash script</h2>

        <picture>
            <source srcset="/media/serverino.avif" type="image/avif">
            <source srcset="/media/serverino.webp" type="image/webp">
            <img class="portfolio-image" src="/media/serverino.jpg" alt="Server-ino" />
        </picture>




        <h3 class="portfolio-subtitle">Mini graphical interface for LAMPP</h3>

        <div class="project-details-content">
            <p>
                A tiny graphical interface for LAMPP, written in Bash and tput (mini graphical library).
                Its purpose is to start a local server without using the command line.
            </p>

            <a href="https://github.com/LorenzoSiena/serverino" class="btn" target="_blank" rel="noopener noreferrer">Go
                to
                project</a>
        </div>
    </div>
    </div>






    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">AI Agent</div>
            <div class="bookmark-tag">Esp32</div>
        </div>


        <h2 class="portfolio-title">Johnny The CyberCar Assistant (Thesis)</h2>


        <picture>
            <source srcset="/media/jhonny.avif" type="image/avif">
            <source srcset="/media/jhonny.webp" type="image/webp">
            <img class="portfolio-image" src="/media/jhonny.jpg" alt="Johnny The CyberCar Assistant Logo" />
        </picture>


        <h3 class="portfolio-subtitle">
            An AI Agent for automotive, RAG enabled, with voice commands, hosted locally.
        </h3>
        <div class="project-details-content">

            <p>
                Johnny The CyberCar Assistant is a proof of concept (PoC) of a fully local RAG-enabled AI agent grafted
                onto an Opel Corsa B from 1997,
                the result of my bachelor's thesis in computer engineering at the University of Catania.
            </p>

            <h4 class="portfolio-section-title"><strong>Project Architecture</strong></h4>
            <p>The project consists of 3 systems:</p>
            <ul>
                <li>
                    <strong>A Linux server with a 1080 TI</strong> on which Cheshire Cat AI runs, the local model
                    (LLAMA3),
                    the voice synthesizer, and speech recognition (Whisper AI).
                </li>
                <li>
                    <strong>A client mounted in the car (Esp32)</strong> with a 4g modem, a microphone, speaker and an
                    Edge speech
                    recognition module with
                    a small machine learning model.
                </li>
                <li>
                    <strong>The ESP32 interfaces with CANBUS</strong> to send and receive vehicle data
                </li>
            </ul>

            <h4 class="portfolio-section-title"><strong>Description and Functionality</strong></h4>
            <p>
                Inspired by

                <strong class="golden"> KITT from Supercar</strong> (aka <a class="golden youtube-link"
                    href="https://www.youtube.com/watch?v=5BsFnk83NMI" target="_blank" rel="noopener noreferrer"> Knight
                    Rider
                    <img src="https://upload.wikimedia.org/wikipedia/commons/4/4f/YouTube_social_white_squircle.svg"
                        alt="YouTube Icon" class="youtube-icon-img"></a>)
                , Johnny makes the car smart: thanks to an ESP32 connected to the CAN BUS and with a 4g modem
                it enables a voice interface, long-term memory and intelligent control (via <b> OBD-II Port</b>) at the
                edge.

                <br>The rest of the AI system is executed remotely on a server with a consumer GPU (GTX 1080TI).
            </p>
            <p>
                The assistant is invoked by the keyword <b>"Hey Johnny!"</b>, after which it is possible to use voice
                commands
                to act locally on
                the car's devices (like raising the windows) or speak voice-to-voice remotely with the Chatbot, which
                responds with
                the context of
                the car's data (GPS position, speed, temperature, etc.), without ever taking your hands off the steering
                wheel.<br>
                The Qdrant vector database manages the assistant's short/long-term
                memory, enabling a true <b>RAG</b> (Retrieval-Augmented Generation) experience.
            </p>
            <p>All services are orchestrated with Docker Compose.</p>

            <h4 class="portfolio-section-title c"><strong>Audio Pipeline</strong></h4>


            <p class="c">
                üé§ User voice<br>
                ‚Üì<br>
                ‚ùì If the command is local ‚Üí executes local action ‚öôÔ∏è<br>
                Otherwise:<br>
                ‚Üì<br>
                üê± contacts johnny the remote chatbot<br>
                ‚Üì<br>
                üåê Cloudflared (authentication) <br>
                ‚Üì<br>
                üìù WhisperAI (Voice2Text on GPU)<br>
                ‚Üì<br>
                üß† LLaMA3 (Ollama, inference on GPU)<br>
                ‚Üì<br>
                üîä Text2Speech (vocal response)<br>
                ‚Üì<br>
                ‚ùì Loop: until it detects ‚Äústop‚Äù, returns to johnny üê±
            </p>
            <h4 class="portfolio-section-title c"><strong>Examples of use</strong></h4>
            <ul class="c">
                <li>"What's the weather like in Amsterdam?" <br>‚Üì<br><strong> "Lorenzo, it's 23 degrees in
                        Amsterdam."</strong></li>
                <li>"Will I arrive in Berlin in time for dinner?"<br>‚Üì<br><strong> "Yes Lorenzo, but you should refuel
                        at the next station
                        33km from
                        here."</strong></li>
                <li>"I heard a strange noise, is something wrong with the car?"<br>‚Üì<br> <strong>"Lorenzo, from your CAN
                        bus
                        I read that you have a
                        problem with the engine, I advise you to pull over as soon as possible."</strong></li>
            </ul>



            <p style="text-align: center; margin-top: 3rem;">
                <em>N.B.</em> The project is completely open-source, it was created in about 2 and a half months,
                it is designed for hardware reuse and edge computing in the automotive sector.
                <br>architecture, images, videos and full thesis in pdf (ITA ONLY) are available in the repository.
            </p>

            <h4 class="portfolio-section-title" style="text-align: center;"><strong>Components developed for the
                    project</strong></h4>
            <ul class="project-components">
                <li class="project-component-item">
                    <p><strong>Local Whisper Cat:</strong> An official Cheshire Cat AI plugin to transcribe locally on
                        your
                        gpu/cpu,
                        in Docker.</p>


                    <picture>
                        <source srcset="/media/local_whisper_cat_logo.avif" type="image/avif">
                        <source srcset="/media/local_whisper_cat_logo.webp" type="image/webp">
                        <img class="portfolio-image" src="/media/local_whisper_cat_logo.jpg"
                            alt="Screenshot Local Whisper Cat" />
                    </picture>


                    <a href="https://github.com/LorenzoSiena/local_whisper_cat" class="btn" target="_blank"
                        rel="noopener noreferrer">GitHub</a>
                </li>
                <li class="project-component-item">
                    <p><strong>Chatty:</strong> Voice client in Python to contact the Cheshire Cat AI server.</p>



                    <picture>
                        <source srcset="/media/chatty_logo.avif" type="image/avif">
                        <source srcset="/media/chatty_logo.webp" type="image/webp">
                        <img class="portfolio-image" src="/media/chatty_logo.jpg" alt="Screenshot Chatty" />
                    </picture>



                    <a href="https://github.com/LorenzoSiena/chatty" class="btn" target="_blank"
                        rel="noopener noreferrer">GitHub</a>
                </li>
                <li class="project-component-item">
                    <p><strong>Chattino:</strong> Arduino/C++ voice client for ESP32 to contact the Cheshire Cat AI
                        server.
                    </p>


                    <picture>
                        <source srcset="/media/chattino_logo.avif" type="image/avif">
                        <source srcset="/media/chattino_logo.webp" type="image/webp">
                        <img class="portfolio-image" src="/media/chattino_logo.jpg" alt="Screenshot Chattino" />
                    </picture>



                    <a href="https://github.com/LorenzoSiena/chattino" class="btn" target="_blank"
                        rel="noopener noreferrer">GitHub</a>

                </li>
            </ul>

            <h4 class="portfolio-section-title" style="text-align: center;"><strong>Technologies used</strong></h4>

            <div class="catbox">

                <div class="image-gallery">
                    <figure>
                        <img class="cat-image" src="/media/jhonny_qrcode.jpg"
                            alt="QR Code generated with Stable Diffusion for the Johnny project" />
                        <figcaption>Scan the QR for the thesis <br>(PDF, ITA)</figcaption>
                    </figure>
                </div>

                <ul>
                    <li>
                        <strong>Cheshire Cat AI Framework</strong> ‚Äî modular platform for AI agents,
                        based on <strong>LangChain</strong> for reasoning management and <strong>FastAPI</strong> for
                        API exposure.
                    </li>
                    <li>
                        <strong>Ollama</strong> ‚Äî local AI backend for executing LLM models, integrated with the
                        framework.
                    </li>
                    <li>
                        <strong>Large Language Models (LLM)</strong> ‚Äî executed via <strong>Ollama</strong> on a
                        <strong>NVIDIA GTX 1080 Ti</strong> GPU.
                    </li>
                    <li>
                        <strong>Qdrant</strong> ‚Äî vector database used for <em>Retrieval-Augmented Generation
                            (RAG)</em>.
                    </li>
                    <li>
                        <strong>Whisper AI</strong> ‚Äî local voice recognition executed on GPU.
                    </li>
                    <li>
                        <strong>Docker & Docker Compose</strong> ‚Äî containerization and service orchestration.
                    </li>
                    <li>
                        <strong>Cloudflared</strong> ‚Äî secure tunnel to expose services in <em>edge computing</em>.
                    </li>
                    <li>
                        <strong>ESP32</strong> + <strong>Arduino</strong> ‚Äî microcontrollers used as interface hardware.
                    </li>
                    <li>
                        <strong>CAN BUS and OBD-II</strong> ‚Äî protocols used for communication with vehicle systems.
                    </li>
                </ul>

                <br>

                <br>
            </div>

            <div class="btn-container">


                <a href="https://github.com/LorenzoSiena/Johnny-The-CyberCar-Assistant" class="btn" target="_blank"
                    rel="noopener noreferrer">
                    Go to project on GitHub
                </a>
                <a href="https://github.com/user-attachments/assets/d688e4d2-7bd9-4638-b752-de8a21699676" class="btn"
                    target="_blank" rel="noopener noreferrer">
                    Watch the Proof of Concept demo video
                </a>
            </div>
        </div>





    </div>







    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">web</div>
        </div>
        <h2 class="portfolio-title">Retro Museum</h2>

        <picture>
            <source srcset="/media/retromuseum_about.avif" type="image/avif">
            <source srcset="/media/retromuseum_about.webp" type="image/webp">
            <img class="portfolio-image" src="/media/retromuseum_about.jpg" alt="Retro Museum" />
        </picture>


        <h3 class="portfolio-subtitle">Fake retro gaming-themed e-commerce in Laravel (PHP)</h3>
        <div class="project-details-content">
            <p>
                Retromuseum is a university web development project for a fake e-commerce of a fictional company from
                Catania,
                where users could buy used games and consoles, with a visual style heavily inspired by classic 8-bit
                graphics.
                <br>Initially the backend was implemented in pure PHP,
                then migrated to Laravel.
            </p>
            <p>

                It uses a pre-populated MySQL database,
                calls the Spotify API (OAuth 2.0) for the latest (fake) podcast available,
                and uses MongoDB as a database for the cart (only to get extra points for the project).
            </p>
            <p>
                It includes a login system, with client/server validation, a search bar and
                dynamically generated content via JS from rawg.io api.
            </p>
            <p> The entire web app is mobile-responsive. </p>
            <a href="https://github.com/LorenzoSiena/Retromuseum" class="btn" target="_blank"
                rel="noopener noreferrer">Go to
                project</a>
        </div>
    </div>

    <h2 class="portfolio-title">Cloud and On Premise Solution Projects</h2>
    <br>
    <div class="portfolio-block">
        <div class="tag-container">
            <div class="bookmark-tag">cloud gaming</div>
        </div>
        <div class="portfolio-text">

            <h2 class="portfolio-title">Cloud Gaming Bare Metal</h2>

            <picture>
                <source srcset="/media/deploy_nes.avif" type="image/avif">
                <source srcset="/media/deploy_nes.webp" type="image/webp">
                <img class="portfolio-image" src="/media/deploy_nes.jpg" alt="Cloud Gaming Bare Metal" />
            </picture>



            <h3 class="portfolio-subtitle">Debian + SNES Emulator + Sunshine</h3>
            <div class="project-details-content">
                <p>
                    A simple <strong>local cloud gaming</strong> solution: on an old laptop
                    it is installed Debian, an SNES emulator, and the <em>Sunshine</em> server.
                    This way it's possible to stream retro games directly on the network and connect remotely
                    with <em>Moonlight</em> client, without containers or virtualization.
                </p>
                <p><strong>Technologies used:</strong></p>
                <ul>
                    <li>Sunshine</li>
                    <li>Moonlight</li>
                    <li>Cloudflared Tunnel</li>
                    <li>Bsnes</li>
                    <li>Raspberry</li>
                    <li>an old PC as a server</li>
                </ul>
                <p><em>N.B.</em> Minimal and zero-cost configuration, designed for hardware recycling.</p>
                <a href="https://www.linkedin.com/posts/activity-7283526476971347969-67ry?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC6mOeoBVQgd4y-2XUOGp19f1HXHsIYpHH8"
                    class="btn" target="_blank" rel="noopener noreferrer">Go to the linkedin post</a>

            </div>

        </div>
    </div>
    <div class="portfolio-block">

        <div class="tag-container">
            <div class="bookmark-tag">local AI</div>
        </div>
        <div class="portfolio-text">

            <h2 class="portfolio-title">Local Chatbot with Docker</h2>

            <picture>
                <source srcset="/media/deploy_ollama.avif" type="image/avif">
                <source srcset="/media/deploy_ollama.webp" type="image/webp">
                <img class="portfolio-image" src="/media/deploy_ollama.jpg" alt="Local Chatbot with Docker" />
            </picture>



            <h3 class="portfolio-subtitle">Ollama + OpenWebUI + Cloudflare Tunnel</h3>
            <div class="project-details-content">

                <p>
                    A private <strong>local chatbot</strong> project, running on an old laptop
                    with <em>Docker</em>. The model (Gemma2 or LLaMA 3.2) runs in an Ollama container
                    with a web interface via OpenWebUI, accessible on port 3000.
                </p>
                <p>
                    It's immediately available on the LAN, while a <strong>Raspberry Pi</strong> with
                    <em>Cloudflare Tunnel</em> securely exposes the service even remotely,
                    via a personalized domain (.xyz) and authentication.
                </p>
                <p><strong>Technologies used:</strong></p>
                <ul>
                    <li><strong>Ollama</strong>: Local-hosted AI backend.</li>
                    <li><strong>LLama3.2 / Gemma2</strong>: Open-source models.</li>
                    <li><strong>OpenWebUI</strong>: Used as the frontend.</li>
                    <li><strong>Docker & NVIDIA Container Toolkit</strong>.</li>
                    <li><strong>Raspberry Pi</strong>: Used as a tunnel and access point.</li>
                    <li><strong>Old PC</strong>: With a GPU or multi-core CPU and at least 4GB of RAM.</li>
                    <li><strong>Cloudflare Tunnel</strong>: For secure remote access.</li>
                </ul>
                <p><em>N.B.</em> Configuration designed to recycle hardware and avoid e-waste.</p>

                <a href="https://www.linkedin.com/posts/activity-7249075606993203200-aQ1q?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC6mOeoBVQgd4y-2XUOGp19f1HXHsIYpHH8"
                    class="btn" target="_blank" rel="noopener noreferrer">Go to the Local Chatbot linkedin post</a>
            </div>
        </div>
    </div>



    <div id="lightbox" class="lightbox">
        <span class="close-btn">&times;</span>
        <img class="lightbox-content" id="lightbox-image" src="" alt="Full size image" />
    </div>
    <button id="scrollToTopBtn" class="scroll-to-top">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
            <path d="M12 2l-10 10h6v10h8v-10h6l-10-10z" />
        </svg>
    </button>

</body>

</html>